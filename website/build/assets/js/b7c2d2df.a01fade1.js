"use strict";(self.webpackChunkgenai_llm_documentation_website=self.webpackChunkgenai_llm_documentation_website||[]).push([[5617],{1843(e){e.exports=JSON.parse('{"tag":{"label":"ollama","permalink":"/gen-ai-llm-docs/docs/tags/ollama","allTagsPath":"/gen-ai-llm-docs/docs/tags","count":1,"items":[{"id":"05-tooling-and-frameworks/03-local-inference","title":"Local Inference","description":"When working with Red Zone data (PII, secrets, core IP), you cannot send code to the cloud. Local inference allows you to execute GenAI & LLM Documentation safely on your own hardware, maintaining data privacy and reducing reliance on external services.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/03-local-inference"}],"unlisted":false}}')}}]);