"use strict";(self.webpackChunkgenai_llm_documentation_website=self.webpackChunkgenai_llm_documentation_website||[]).push([[9345],{78467(e){e.exports=JSON.parse('{"tag":{"label":"failure-modes","permalink":"/gen-ai-llm-docs/docs/tags/failure-modes","allTagsPath":"/gen-ai-llm-docs/docs/tags","count":3,"items":[{"id":"01-handbook-core-method/core-skills/06-common-skill-gaps","title":"Common Skill Gaps","description":"Most GenAI & LLM Documentation failures are not caused by bad tools or weak models. They are caused by human skill gaps that go unaddressed.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/core-skills/06-common-skill-gaps"},{"id":"04-responsible-ai/02-hallucinations","title":"Hallucinations and Failure Modes","description":"Identify common failures, why they occur, and how the methods in this documentation help mitigate them. Understanding these modes is crucial for building reliable AI-assisted workflows and prevents over-reliance on AI.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/02-hallucinations"},{"id":"foundations/02-llm-deep-dive/fundamentals/07-hallucinations-and-failure-modes","title":"Hallucinations and Failure Modes","description":"Identify common failures, why they occur, and how GenAI & LLM Documentation mitigates them. Understanding these modes is crucial for building reliable AI-assisted workflows and prevents over-reliance on AI.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/07-hallucinations-and-failure-modes"}],"unlisted":false}}')}}]);