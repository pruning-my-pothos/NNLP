"use strict";(self.webpackChunkgenai_llm_documentation_website=self.webpackChunkgenai_llm_documentation_website||[]).push([[5914],{99911(e){e.exports=JSON.parse('{"tag":{"label":"tooling","permalink":"/gen-ai-llm-docs/docs/tags/tooling","allTagsPath":"/gen-ai-llm-docs/docs/tags","count":4,"items":[{"id":"05-tooling-and-frameworks/02-cli-agents","title":"CLI Agents","description":"CLI agents (like Aider) enable autonomous, iterative execution of tasks directly within your code editor. They streamline repetitive coding tasks, refactorings, and test generation by operating on local files, making them ideal for integrating with existing developer workflows.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/02-cli-agents"},{"id":"05-tooling-and-frameworks/01-ide-setup-cursor","title":"IDE Setup: Cursor","description":"Cursor is currently the preferred IDE for GenAI & LLM Documentation because it treats Context Injection as a first-class feature. You can explicitly reference your specs using @Symbols, making the GenAI & LLM Documentation Loop frictionless.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/01-ide-setup-cursor"},{"id":"05-tooling-and-frameworks/03-local-inference","title":"Local Inference","description":"When working with Red Zone data (PII, secrets, core IP), you cannot send code to the cloud. Local inference allows you to execute GenAI & LLM Documentation safely on your own hardware, maintaining data privacy and reducing reliance on external services.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/03-local-inference"},{"id":"05-tooling-and-frameworks/00-tooling-index","title":"Tooling Index","description":"The tool is not the method. A carpenter can use a hand saw or a power saw, but the geometry of the cut remains the same. GenAI & LLM Documentation works with any tool that allows context injection and structured interaction.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/00-tooling-index"}],"unlisted":false}}')}}]);