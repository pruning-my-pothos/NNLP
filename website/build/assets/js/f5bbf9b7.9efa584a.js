"use strict";(self.webpackChunkgenai_llm_documentation_website=self.webpackChunkgenai_llm_documentation_website||[]).push([[7118],{67276(e){e.exports=JSON.parse('{"tag":{"label":"security","permalink":"/gen-ai-llm-docs/docs/tags/security","allTagsPath":"/gen-ai-llm-docs/docs/tags","count":5,"items":[{"id":"04-responsible-ai/data-boundaries","title":"Data Boundaries","description":"Explicitly define what data types can (and cannot) be exposed to AI tools. This guardrail is critical for protecting sensitive information, ensuring compliance with data privacy regulations, and preventing data leakage in AI-assisted workflows.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/data-boundaries"},{"id":"03-professional-scenarios/02-refactoring-legacy-auth","title":"Scenario: Refactoring Legacy Auth","description":"Safely refactor a critical, complex legacy authentication system without introducing regressions or security vulnerabilities, leveraging AI to generate characterization tests and apply incremental changes.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/02-refactoring-legacy-auth"},{"id":"03-professional-scenarios/advanced-scenarios/02-refactoring-legacy-auth","title":"Scenario: Refactoring Legacy Auth","description":"Safely refactor a critical, complex legacy authentication system without introducing regressions or security vulnerabilities, leveraging AI to generate characterization tests and apply incremental changes.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/advanced-scenarios/02-refactoring-legacy-auth"},{"id":"06-templates/threat-model-lite-template","title":"Template: Threat Model Lite","description":"Fill this out for any feature that uses an LLM. If you answer \\"Yes\\" to any High Risk item, you must have a specific mitigation listed.","permalink":"/gen-ai-llm-docs/docs/06-templates/threat-model-lite-template"},{"id":"04-responsible-ai/threat-model-lite","title":"Threat Model Lite","description":"Quickly identify and mitigate security risks associated with AI-assisted development. This lightweight threat modeling approach focuses on AI-specific vulnerabilities and ensures that security considerations are embedded early in the GenAI & LLM Documentation Loop.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/threat-model-lite"}],"unlisted":false}}')}}]);