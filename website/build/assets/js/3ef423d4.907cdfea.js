"use strict";(self.webpackChunkgenai_llm_documentation_website=self.webpackChunkgenai_llm_documentation_website||[]).push([[3092],{27094(e){e.exports=JSON.parse('{"tag":{"label":"method","permalink":"/gen-ai-llm-docs/docs/tags/method","allTagsPath":"/gen-ai-llm-docs/docs/tags","count":13,"items":[{"id":"01-handbook-core-method/acceptance-criteria","title":"Acceptance Criteria","description":"Define objective, measurable conditions that must be met for an AI-generated output to be considered \\"done.\\" This transforms subjective \\"looks good\\" into evidence-based \\"is good,\\" preventing premature acceptance and ensuring quality.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/acceptance-criteria"},{"id":"01-handbook-core-method/constraint-spec","title":"Constraint Spec","description":"Encode all non-negotiable boundaries, technical requirements, and guardrails for an AI-assisted task. This prevents AI overreach, ensures compliance with architectural standards, and mitigates risks from hallucinations or unintended behavior.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/constraint-spec"},{"id":"01-handbook-core-method/delegation-contract","title":"Delegation Contract","description":"Explicitly define the scope of authority granted to an AI tool for a specific task. This prevents AI overreach, ensures adherence to security and architectural boundaries, and clarifies where AI can act autonomously versus where human intervention is required.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/delegation-contract"},{"id":"01-handbook-core-method/discovery-brief","title":"Discovery Brief","description":"Clarify the problem space, identify stakeholders, and gather essential context without proposing solutions. This artifact ensures a shared understanding of what problem needs solving before jumping to how to solve it with AI.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/discovery-brief"},{"id":"01-handbook-core-method/generation-requests","title":"Generation Requests","description":"Formulate precise and structured prompts to AI, combining Intent, Constraints, and Delegation Contract into an executable instruction. This maximizes the relevance and quality of AI-generated outputs, reducing iteration cycles.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/generation-requests"},{"id":"01-handbook-core-method/08-evaluation/03-human-review-protocols","title":"Human Review Protocols","description":"Systematically verify AI-generated outputs against your Intent and Constraint Specs. This is where human judgment ensures correctness, safety, and alignment before acceptance.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/08-evaluation/03-human-review-protocols"},{"id":"01-handbook-core-method/02-ideation-and-use-case","title":"Ideation and Use Case Definition","description":"Clarify the problem space, identify stakeholders, and gather essential context without proposing solutions. This artifact ensures a shared understanding of what problem needs solving before jumping to how to solve it with AI.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/02-ideation-and-use-case"},{"id":"01-handbook-core-method/intent-spec","title":"Intent Spec","description":"Clearly define the desired outcome and success criteria for an AI-assisted task. This prevents scope creep, focuses AI generation, and provides a clear benchmark for evaluating outputs.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/intent-spec"},{"id":"01-handbook-core-method/iteration-and-release","title":"Iteration and Release","description":"Integrate feedback, iterate on AI-generated outputs, and systematically release accepted artifacts. This step emphasizes continuous improvement of both the AI-assisted work and the GenAI & LLM Documentation process itself, ensuring lessons learned are fed back into the loop.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/iteration-and-release"},{"id":"01-handbook-core-method/review-and-interrogation","title":"Review and Interrogation","description":"Systematically verify AI-generated outputs against your Intent and Constraint Specs. This is where human judgment ensures correctness, safety, and alignment before acceptance.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/review-and-interrogation"},{"id":"01-handbook-core-method/the-genai-llm-loop","title":"The GenAI & LLM Documentation Loop","description":"The GenAI & LLM Documentation Loop is the engine of the framework. It turns abstract intent into concrete, reviewable artifacts through a repeatable 8-step process.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/the-genai-llm-loop"},{"id":"04-responsible-ai/threat-model-lite","title":"Threat Model Lite","description":"Quickly identify and mitigate security risks associated with AI-assisted development. This lightweight threat modeling approach focuses on AI-specific vulnerabilities and ensures that security considerations are embedded early in the GenAI & LLM Documentation Loop.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/threat-model-lite"},{"id":"01-handbook-core-method/working-agreements-for-teams","title":"Working Agreements for Teams","description":"Establish clear, shared rules for how a team will collaborate with AI. These agreements foster a culture of accountability, trust, and effective AI integration, preventing friction and maximizing the benefits of GenAI & LLM Documentation.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/working-agreements-for-teams"}],"unlisted":false}}')}}]);