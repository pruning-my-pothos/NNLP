"use strict";(self.webpackChunkgenai_llm_documentation_website=self.webpackChunkgenai_llm_documentation_website||[]).push([[8255],{64599(e){e.exports=JSON.parse('{"tag":{"label":"genai-llm","permalink":"/gen-ai-llm-docs/docs/tags/genai-llm","allTagsPath":"/gen-ai-llm-docs/docs/tags","count":108,"items":[{"id":"01-handbook-core-method/acceptance-criteria","title":"Acceptance Criteria","description":"Define objective, measurable conditions that must be met for an AI-generated output to be considered \\"done.\\" This transforms subjective \\"looks good\\" into evidence-based \\"is good,\\" preventing premature acceptance and ensuring quality.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/acceptance-criteria"},{"id":"06-templates/acceptance-criteria-template","title":"Acceptance Criteria Template","description":"Define objective, measurable conditions that must be met for an AI-generated output to be considered \\"done.\\" This transforms subjective \\"looks good\\" into evidence-based \\"is good,\\" preventing premature acceptance and ensuring quality.","permalink":"/gen-ai-llm-docs/docs/06-templates/acceptance-criteria-template"},{"id":"04-responsible-ai/01-accountability-and-delegation","title":"Accountability and Delegation Model","description":"Clarify roles, responsibilities, and decision-making authority when working with AI. This model ensures that humans remain accountable for outcomes, even when delegating tasks to AI tools.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/01-accountability-and-delegation"},{"id":"04-responsible-ai/accountability-model","title":"Accountability Model","description":"AI is a tool, not a colleague. It cannot be fired, sued, or held responsible. Therefore, a human must own every output.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/accountability-model"},{"id":"03-professional-scenarios/advanced-scenarios/00-index","title":"Advanced Scenarios Index","description":"Theory is clean. Reality is messy. These scenarios are \\"game tapes\\" of real GenAI & LLM execution, showing the messy middle where trade-offs happen, and how to apply the framework to overcome challenges.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/advanced-scenarios/00-index"},{"id":"foundations/02-llm-deep-dive/fundamentals/06-agents-and-orchestration-basics","title":"Agents and Orchestration Basics","description":"Outline when to use agents, how to bound them, and how to orchestrate safely.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/06-agents-and-orchestration-basics"},{"id":"01-handbook-core-method/08-evaluation/02-automated-evaluation","title":"Automated Evaluation","description":"In GenAI & LLM Documentation, we treat evaluation as a pipeline, not just a meeting. Configure your CLI agent (e.g., Aider) to run these checks before asking for human review.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/08-evaluation/02-automated-evaluation"},{"id":"04-responsible-ai/bias","title":"Bias and Fairness","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/bias"},{"id":"CHANGELOG","title":"Changelog","description":"This is a placeholder for consolidated release notes. For now, refer to repository history and PR descriptions.","permalink":"/gen-ai-llm-docs/docs/CHANGELOG"},{"id":"05-tooling-and-frameworks/02-cli-agents","title":"CLI Agents","description":"CLI agents (like Aider) enable autonomous, iterative execution of tasks directly within your code editor. They streamline repetitive coding tasks, refactorings, and test generation by operating on local files, making them ideal for integrating with existing developer workflows.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/02-cli-agents"},{"id":"01-handbook-core-method/core-skills/06-common-skill-gaps","title":"Common Skill Gaps","description":"Most GenAI & LLM Documentation failures are not caused by bad tools or weak models. They are caused by human skill gaps that go unaddressed.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/core-skills/06-common-skill-gaps"},{"id":"01-handbook-core-method/constraint-spec","title":"Constraint Spec","description":"Encode all non-negotiable boundaries, technical requirements, and guardrails for an AI-assisted task. This prevents AI overreach, ensures compliance with architectural standards, and mitigates risks from hallucinations or unintended behavior.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/constraint-spec"},{"id":"06-templates/constraint-spec-template","title":"Constraint Spec Template","description":"Encode all non-negotiable boundaries, technical requirements, and guardrails for an AI-assisted task. This prevents AI overreach, ensures compliance with architectural standards, and mitigates risks from hallucinations or unintended behavior.","permalink":"/gen-ai-llm-docs/docs/06-templates/constraint-spec-template"},{"id":"foundations/02-llm-deep-dive/fundamentals/02-context-windows-and-token-economics","title":"Context Windows and Token Economics","description":"Help practitioners budget context, avoid truncation, and manage cost/latency trade-offs.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/02-context-windows-and-token-economics"},{"id":"foundations/02-llm-deep-dive/copilots","title":"Copilots","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/copilots"},{"id":"01-handbook-core-method/core-skills/00-core-skills-overview","title":"Core Skills Overview","description":"Tools don\u2019t make GenAI & LLM Documentation work\u2014people do. These four skills determine whether AI accelerates you or creates risk.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/core-skills/00-core-skills-overview"},{"id":"01-handbook-core-method/cost-intuition","title":"Cost Intuition","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/cost-intuition"},{"id":"04-responsible-ai/data-boundaries","title":"Data Boundaries","description":"Explicitly define what data types can (and cannot) be exposed to AI tools. This guardrail is critical for protecting sensitive information, ensuring compliance with data privacy regulations, and preventing data leakage in AI-assisted workflows.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/data-boundaries"},{"id":"01-handbook-core-method/delegation-contract","title":"Delegation Contract","description":"Explicitly define the scope of authority granted to an AI tool for a specific task. This prevents AI overreach, ensures adherence to security and architectural boundaries, and clarifies where AI can act autonomously versus where human intervention is required.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/delegation-contract"},{"id":"01-handbook-core-method/discovery-brief","title":"Discovery Brief","description":"Clarify the problem space, identify stakeholders, and gather essential context without proposing solutions. This artifact ensures a shared understanding of what problem needs solving before jumping to how to solve it with AI.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/discovery-brief"},{"id":"foundations/02-llm-deep-dive/emergent-abilities","title":"Emergent Abilities","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/emergent-abilities"},{"id":"04-responsible-ai/environmental-ai","title":"Environmental AI","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/environmental-ai"},{"id":"04-responsible-ai/ethical-ai","title":"Ethical AI","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/ethical-ai"},{"id":"01-handbook-core-method/evaluation","title":"Evaluation","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/evaluation"},{"id":"01-handbook-core-method/08-evaluation/00-eval-overview","title":"Evaluation Overview","description":"Evaluation shifts \\"looks good\\" to \\"is good,\\" providing objective evidence that AI-assisted work meets quality and performance criteria.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/08-evaluation/00-eval-overview"},{"id":"01-handbook-core-method/execution-patterns/00-index","title":"Execution Patterns Index","description":"Execution patterns are reusable recipes for applying the GenAI Project Lifecycle to common development tasks. They provide step-by-step guidance on how to achieve specific outcomes, from creating new components to refactoring legacy code.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/execution-patterns/00-index"},{"id":"02-execution-patterns/00-pattern-index","title":"Execution Patterns Index","description":"Execution patterns are reusable recipes for applying GenAI & LLM Documentation to common development tasks. They provide step-by-step guidance on how to achieve specific outcomes, from creating new components to refactoring legacy code.","permalink":"/gen-ai-llm-docs/docs/02-execution-patterns/00-pattern-index"},{"id":"06-templates/experiment-template","title":"Experiment: [Experiment Name]","description":"We believe that [doing X] with [Model Y] will result in [Outcome Z].","permalink":"/gen-ai-llm-docs/docs/06-templates/experiment-template"},{"id":"04-responsible-ai/explainable-ai","title":"Explainable AI","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/explainable-ai"},{"id":"01-handbook-core-method/fine-tuning","title":"Fine-tuning","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/fine-tuning"},{"id":"01-handbook-core-method/accountability-and-delegation","title":"GenAI & LLM Documentation Accountability and Delegation Model","description":"Clarify roles, responsibilities, and decision-making authority when working with AI. This model ensures that humans remain accountable for outcomes, even when delegating tasks to AI tools.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/accountability-and-delegation"},{"id":"AGENTS","title":"GenAI & LLM Documentation Agent Instructions for Codex","description":"Overview","permalink":"/gen-ai-llm-docs/docs/AGENTS"},{"id":"01-handbook-core-method/artifact-contracts","title":"GenAI & LLM Documentation Artifact Contracts (Normative)","description":"Define the expected structure, content, and quality of each artifact produced throughout the GenAI & LLM Documentation Loop. This ensures consistency, facilitates efficient review, and establishes a clear understanding of deliverables.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/artifact-contracts"},{"id":"01-handbook-core-method/genai-llm-loop-spec","title":"GenAI & LLM Documentation Loop: Normative Process Model","description":"Define the required GenAI & LLM Documentation workflow so teams can adopt it consistently. This ensures repeatable, auditable execution from problem definition to acceptance.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/genai-llm-loop-spec"},{"id":"00-handbook-introduction/prerequisites-and-entry-criteria","title":"GenAI & LLM Handbook: Prerequisites and Entry Criteria","description":"Formalize the skill gate to prevent Level 0 usage from declaring the GenAI & LLM Handbook \u201cbroken.\u201d Establish minimum and recommended prerequisites before applying the GenAI & LLM Handbook.","permalink":"/gen-ai-llm-docs/docs/00-handbook-introduction/prerequisites-and-entry-criteria"},{"id":"00-handbook-introduction/scope-and-applicability","title":"GenAI & LLM Handbook: Scope and Applicability","description":"Draw a clear boundary for when the GenAI & LLM Handbook applies, what it governs, and when it may be skipped. Define \u201cprofessional environment\u201d in impact terms, not job titles.","permalink":"/gen-ai-llm-docs/docs/00-handbook-introduction/scope-and-applicability"},{"id":"foundations/02-llm-deep-dive/fundamentals/10-genai-product-lifecycle","title":"GenAI Product Lifecycle","description":"Integrate Generative AI capabilities into your product development lifecycle, from ideation to deployment and maintenance. This guide ensures that AI features are developed responsibly, align with user needs, and are governed effectively, leveraging GenAI & LLM Documentation principles throughout.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/10-genai-product-lifecycle"},{"id":"01-handbook-core-method/01-overview","title":"GenAI Project Lifecycle Overview","description":"Integrate Generative AI capabilities into your project development lifecycle, from ideation to deployment and maintenance. This guide ensures that AI features are developed responsibly, align with user needs, and are governed effectively.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/01-overview"},{"id":"06-templates/generation-request-template","title":"Generation Request Template","description":"Formulate precise and structured prompts to AI, combining Intent and Constraints into an executable instruction. This maximizes the relevance and quality of AI-generated outputs, reducing iteration cycles.","permalink":"/gen-ai-llm-docs/docs/06-templates/generation-request-template"},{"id":"01-handbook-core-method/generation-requests","title":"Generation Requests","description":"Formulate precise and structured prompts to AI, combining Intent, Constraints, and Delegation Contract into an executable instruction. This maximizes the relevance and quality of AI-generated outputs, reducing iteration cycles.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/generation-requests"},{"id":"00-handbook-introduction/glossary","title":"Glossary","description":"Clear, consistent terminology is fundamental for effective communication with both humans and AI. This glossary defines key terms used throughout the GenAI & LLM Handbook.","permalink":"/gen-ai-llm-docs/docs/00-handbook-introduction/glossary"},{"id":"04-responsible-ai/guardrails-index","title":"Guardrails and Governance Index","description":"Guardrails and Governance define the protective measures and policies necessary to ensure AI is used safely, ethically, and in compliance with organizational and regulatory standards. These are critical for managing the risks inherent in AI-assisted development.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/guardrails-index"},{"id":"04-responsible-ai/02-hallucinations","title":"Hallucinations and Failure Modes","description":"Identify common failures, why they occur, and how the methods in this documentation help mitigate them. Understanding these modes is crucial for building reliable AI-assisted workflows and prevents over-reliance on AI.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/02-hallucinations"},{"id":"foundations/02-llm-deep-dive/fundamentals/07-hallucinations-and-failure-modes","title":"Hallucinations and Failure Modes","description":"Identify common failures, why they occur, and how GenAI & LLM Documentation mitigates them. Understanding these modes is crucial for building reliable AI-assisted workflows and prevents over-reliance on AI.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/07-hallucinations-and-failure-modes"},{"id":"00-handbook-introduction/how-to-use-this-repo","title":"How to Use This Repository","description":"This repository is designed to be a practical guide for using Generative AI and LLMs in AI-assisted development. Choose your path based on your role and current needs.","permalink":"/gen-ai-llm-docs/docs/00-handbook-introduction/how-to-use-this-repo"},{"id":"01-handbook-core-method/08-evaluation/03-human-review-protocols","title":"Human Review Protocols","description":"Systematically verify AI-generated outputs against your Intent and Constraint Specs. This is where human judgment ensures correctness, safety, and alignment before acceptance.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/08-evaluation/03-human-review-protocols"},{"id":"05-tooling-and-frameworks/01-ide-setup-cursor","title":"IDE Setup: Cursor","description":"Cursor is currently the preferred IDE for GenAI & LLM Documentation because it treats Context Injection as a first-class feature. You can explicitly reference your specs using @Symbols, making the GenAI & LLM Documentation Loop frictionless.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/01-ide-setup-cursor"},{"id":"01-handbook-core-method/02-ideation-and-use-case","title":"Ideation and Use Case Definition","description":"Clarify the problem space, identify stakeholders, and gather essential context without proposing solutions. This artifact ensures a shared understanding of what problem needs solving before jumping to how to solve it with AI.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/02-ideation-and-use-case"},{"id":"01-handbook-core-method/instruction-tuning","title":"Instruction Tuning","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/instruction-tuning"},{"id":"01-handbook-core-method/intent-spec","title":"Intent Spec","description":"Clearly define the desired outcome and success criteria for an AI-assisted task. This prevents scope creep, focuses AI generation, and provides a clear benchmark for evaluating outputs.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/intent-spec"},{"id":"06-templates/intent-spec-template","title":"Intent Spec Template","description":"Clearly define the desired outcome and success criteria for an AI-assisted task. This prevents scope creep, focuses AI generation, and provides a clear benchmark for evaluating outputs.","permalink":"/gen-ai-llm-docs/docs/06-templates/intent-spec-template"},{"id":"01-handbook-core-method/iteration-and-release","title":"Iteration and Release","description":"Integrate feedback, iterate on AI-generated outputs, and systematically release accepted artifacts. This step emphasizes continuous improvement of both the AI-assisted work and the GenAI & LLM Documentation process itself, ensuring lessons learned are fed back into the loop.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/iteration-and-release"},{"id":"01-handbook-core-method/core-skills/02-language","title":"Language","description":"In GenAI & LLM Documentation, language is a specification medium. Ambiguity is a defect, not a style choice.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/core-skills/02-language"},{"id":"LICENSE","title":"License","description":"Creative Commons Legal Code","permalink":"/gen-ai-llm-docs/docs/LICENSE"},{"id":"01-handbook-core-method/cheat-sheet","title":"Lifecycle Cheat Sheet","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/cheat-sheet"},{"id":"foundations/02-llm-deep-dive/list-of-foundation-models","title":"List of Foundation Models","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/list-of-foundation-models"},{"id":"foundations/02-llm-deep-dive/llm-characteristics","title":"LLM Characteristics","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/llm-characteristics"},{"id":"05-tooling-and-frameworks/03-local-inference","title":"Local Inference","description":"When working with Red Zone data (PII, secrets, core IP), you cannot send code to the cloud. Local inference allows you to execute GenAI & LLM Documentation safely on your own hardware, maintaining data privacy and reducing reliance on external services.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/03-local-inference"},{"id":"01-handbook-core-method/core-skills/01-logic","title":"Logic","description":"Logic defines the \\"rules of the game\\" for AI. If your rules are fuzzy, your AI will lose the match.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/core-skills/01-logic"},{"id":"01-handbook-core-method/08-evaluation/04-metrics-and-kpis","title":"Metrics and KPIs","description":"How do you know if GenAI & LLM Documentation is working? These metrics help you measure the quality and efficiency of your AI adoption, moving beyond \\"it feels faster.\\"","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/08-evaluation/04-metrics-and-kpis"},{"id":"01-handbook-core-method/03-model-selection","title":"Model Selection and Tradeoffs","description":"Understand the critical factors for choosing the right LLM for your tasks. Different models offer varying capabilities, costs, and ethical considerations. Making an informed choice optimizes performance, manages expenses, and aligns with project requirements.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/03-model-selection"},{"id":"foundations/02-llm-deep-dive/fundamentals/08-model-selection-and-tradeoffs","title":"Model Selection and Tradeoffs","description":"Understand the critical factors for choosing the right LLM for your GenAI & LLM Documentation tasks. Different models offer varying capabilities, costs, and ethical considerations. Making an informed choice optimizes performance, manages expenses, and aligns with project requirements.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/08-model-selection-and-tradeoffs"},{"id":"foundations/02-llm-deep-dive/openai-playground","title":"OpenAI Playground","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/openai-playground"},{"id":"01-handbook-core-method/peft","title":"Parameter-Efficient Fine-tuning (PEFT)","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/peft"},{"id":"foundations/02-llm-deep-dive/parameter-top-k-vs-top-p-sampling","title":"Parameter: Top-k vs Top-p Sampling","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/parameter-top-k-vs-top-p-sampling"},{"id":"foundations/02-llm-deep-dive/parameters","title":"Parameters","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/parameters"},{"id":"06-templates/pattern-template","title":"Pattern: [Pattern Name]","description":"One sentence explaining why this pattern exists and what problem it solves.","permalink":"/gen-ai-llm-docs/docs/06-templates/pattern-template"},{"id":"02-execution-patterns/07-rubber-duck","title":"Pattern: The Rubber Duck","description":"Use this pattern to debug complex logic or understand legacy code. It forces the AI to explain the code\'s behavior step-by-step, often revealing the bug before you even ask for a fix.","permalink":"/gen-ai-llm-docs/docs/02-execution-patterns/07-rubber-duck"},{"id":"03-professional-scenarios/00-scenarios-index","title":"Professional Scenarios Index","description":"Theory is clean. Reality is messy. These scenarios are \\"game tapes\\" of real GenAI & LLM Documentation execution, showing the messy middle where trade-offs happen, and how to apply the framework to overcome challenges.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/00-scenarios-index"},{"id":"01-handbook-core-method/prompt-engineering","title":"Prompt Engineering","description":"Contrast ad-hoc prompting with disciplined specification so GenAI & LLM work stays predictable. This distinction is fundamental for moving from experimental AI use to reliable, production-ready AI-assisted development.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/prompt-engineering"},{"id":"foundations/02-llm-deep-dive/fundamentals/03-prompting-vs-specifying","title":"Prompting vs. Specifying","description":"Contrast ad-hoc prompting with disciplined specification so GenAI & LLM Documentation stays predictable. This distinction is fundamental for moving from experimental AI use to reliable, production-ready AI-assisted development.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/03-prompting-vs-specifying"},{"id":"01-handbook-core-method/08-evaluation/01-quality-rubric","title":"Quality Rubric","description":"This rubric converts \\"it looks good\\" into a measurable score. Use it to grade AI outputs objectively before acceptance.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/08-evaluation/01-quality-rubric"},{"id":"foundations/02-llm-deep-dive/fundamentals/04-retrieval-and-grounding-rag","title":"Retrieval and Grounding (RAG)","description":"Ground LLM responses in verifiable, up-to-date information, reducing hallucinations and improving factual accuracy. RAG (Retrieval Augmented Generation) is a key technique for ensuring LLMs operate within a defined knowledge base, making their outputs more reliable for GenAI & LLM Documentation tasks.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/04-retrieval-and-grounding-rag"},{"id":"01-handbook-core-method/05-rag","title":"Retrieval Augmented Generation (RAG)","description":"Ground LLM responses in verifiable, up-to-date information, reducing hallucinations and improving factual accuracy. RAG (Retrieval Augmented Generation) is a key technique for ensuring LLMs operate within a defined knowledge base, making their outputs more reliable.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/05-rag"},{"id":"01-handbook-core-method/review-and-interrogation","title":"Review and Interrogation","description":"Systematically verify AI-generated outputs against your Intent and Constraint Specs. This is where human judgment ensures correctness, safety, and alignment before acceptance.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/review-and-interrogation"},{"id":"01-handbook-core-method/risks-production-challenges","title":"Risks & Production Challenges","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/risks-production-challenges"},{"id":"01-handbook-core-method/08-evaluation/05-scenario-scorecards","title":"Scenario Scorecards","description":"A Scenario Scorecard evaluates the entire lifecycle of an AI-assisted task. It answers: \\"Did the GenAI & LLM Documentation process actually work, or did we just generate code fast?\\"","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/08-evaluation/05-scenario-scorecards"},{"id":"06-templates/scenario-template","title":"Scenario: [Scenario Name]","description":"Demonstrate how to apply GenAI & LLM Documentation to [specific task] to achieve [specific outcome] while mitigating [specific risk].","permalink":"/gen-ai-llm-docs/docs/06-templates/scenario-template"},{"id":"03-professional-scenarios/04-cicd-pipeline-migration","title":"Scenario: CI/CD Pipeline Migration","description":"Automate the migration of CI/CD pipelines from one platform to another (e.g., Jenkins to GitHub Actions), leveraging AI to translate existing configurations and identify potential compatibility issues, thereby reducing manual effort and migration errors.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/04-cicd-pipeline-migration"},{"id":"03-professional-scenarios/01-greenfield-react-component","title":"Scenario: Greenfield React Component","description":"Demonstrate how to apply GenAI & LLM Documentation to build a reusable, accessible React component from scratch without introducing technical debt or accessibility violations, accelerating development while maintaining quality.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/01-greenfield-react-component"},{"id":"03-professional-scenarios/advanced-scenarios/01-greenfield-react-component","title":"Scenario: Greenfield React Component","description":"Demonstrate how to apply these methods to build a reusable, accessible React component from scratch without introducing technical debt or accessibility violations, accelerating development while maintaining quality.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/advanced-scenarios/01-greenfield-react-component"},{"id":"03-professional-scenarios/02-refactoring-legacy-auth","title":"Scenario: Refactoring Legacy Auth","description":"Safely refactor a critical, complex legacy authentication system without introducing regressions or security vulnerabilities, leveraging AI to generate characterization tests and apply incremental changes.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/02-refactoring-legacy-auth"},{"id":"03-professional-scenarios/advanced-scenarios/02-refactoring-legacy-auth","title":"Scenario: Refactoring Legacy Auth","description":"Safely refactor a critical, complex legacy authentication system without introducing regressions or security vulnerabilities, leveraging AI to generate characterization tests and apply incremental changes.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/advanced-scenarios/02-refactoring-legacy-auth"},{"id":"03-professional-scenarios/03-writing-a-prd","title":"Scenario: Writing a PRD","description":"Demonstrate how to use GenAI & LLM Documentation to turn vague stakeholder requests into a rigorous Product Requirement Document (PRD) that engineers can actually build, minimizing ambiguity and maximizing clarity.","permalink":"/gen-ai-llm-docs/docs/03-professional-scenarios/03-writing-a-prd"},{"id":"01-handbook-core-method/core-skills/04-sentences","title":"Sentences","description":"Sentences carry instructions, constraints, and priorities. Tiny wording changes can flip behavior.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/core-skills/04-sentences"},{"id":"01-handbook-core-method/core-skills/05-skill-matrix-and-progression","title":"Skill Matrix and Progression","description":"Most AI-assisted failures come from overestimating skill. Use this matrix to see where you stand and where to level up.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/core-skills/05-skill-matrix-and-progression"},{"id":"00-handbook-introduction/standard-core","title":"Standard Core (The GenAI & LLM Handbook)","description":"Use this as the fast entry point to the normative GenAI & LLM Handbook standard. These are the minimal documents required to apply the GenAI & LLM Handbook correctly.","permalink":"/gen-ai-llm-docs/docs/00-handbook-introduction/standard-core"},{"id":"foundations/02-llm-deep-dive/fundamentals/05-structured-output-and-tool-use","title":"Structured Output and Tool Use","description":"Move beyond natural language generation to enable LLMs to produce data in predictable formats (e.g., JSON, YAML, XML) and interact with external systems (APIs, databases). This is essential for integrating LLMs into automated workflows and building reliable AI-assisted applications within GenAI & LLM Documentation.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/fundamentals/05-structured-output-and-tool-use"},{"id":"01-handbook-core-method/core-skills/03-systems","title":"Systems","description":"Systems thinking ensures that AI-generated solutions don\'t break when integrated, scaled, or maintained. It\u2019s about understanding context.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/core-skills/03-systems"},{"id":"foundations/02-llm-deep-dive/temperature","title":"Temperature","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/foundations/02-llm-deep-dive/temperature"},{"id":"06-templates/delegation-contract-template","title":"Template: Delegation Contract","description":"Use this to set the rules of engagement. Paste this into your chat or system prompt before starting the work.","permalink":"/gen-ai-llm-docs/docs/06-templates/delegation-contract-template"},{"id":"06-templates/discovery-brief-template","title":"Template: Discovery Brief","description":"Fill this out before writing any prompts or code. Keep it short. If you can\'t fill a section, pause and investigate.","permalink":"/gen-ai-llm-docs/docs/06-templates/discovery-brief-template"},{"id":"06-templates/iteration-log-template","title":"Template: Iteration Log","description":"Use this log when the first attempt fails. Do not just \\"regenerate.\\" Document what you changed in the specs to fix the error.","permalink":"/gen-ai-llm-docs/docs/06-templates/iteration-log-template"},{"id":"06-templates/quality-rubric-template","title":"Template: Quality Rubric","description":"Grade the artifact (code file, doc, etc.) on a scale of 1-3 for each dimension.","permalink":"/gen-ai-llm-docs/docs/06-templates/quality-rubric-template"},{"id":"06-templates/review-and-interrogation-template","title":"Template: Review & Interrogation","description":"Do not merge AI code without this review. Check the boxes based on evidence, not \\"it looks good.\\"","permalink":"/gen-ai-llm-docs/docs/06-templates/review-and-interrogation-template"},{"id":"06-templates/scenario-scorecard-template","title":"Template: Scenario Scorecard","description":"Use this scorecard to grade an end-to-end AI session. Be honest. If you skipped a step, mark it as skipped.","permalink":"/gen-ai-llm-docs/docs/06-templates/scenario-scorecard-template"},{"id":"06-templates/threat-model-lite-template","title":"Template: Threat Model Lite","description":"Fill this out for any feature that uses an LLM. If you answer \\"Yes\\" to any High Risk item, you must have a specific mitigation listed.","permalink":"/gen-ai-llm-docs/docs/06-templates/threat-model-lite-template"},{"id":"06-templates/working-agreements-template","title":"Template: Working Agreements","description":"Use this template to align your team on how AI tools will be used. These are not just rules; they are promises you make to each other to maintain quality and trust.","permalink":"/gen-ai-llm-docs/docs/06-templates/working-agreements-template"},{"id":"06-templates/00-templates-index","title":"Templates","description":"Don\'t start from a blank page. These templates provide the structure you need to execute GenAI & LLM Documentation effectively. Copy them, fill them out, and treat them as source code.","permalink":"/gen-ai-llm-docs/docs/06-templates/00-templates-index"},{"id":"01-handbook-core-method/testing-tools","title":"Testing Tools","description":"Placeholder content. Outline the key points and examples for this topic.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/testing-tools"},{"id":"01-handbook-core-method/the-genai-llm-loop","title":"The GenAI & LLM Documentation Loop","description":"The GenAI & LLM Documentation Loop is the engine of the framework. It turns abstract intent into concrete, reviewable artifacts through a repeatable 8-step process.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/the-genai-llm-loop"},{"id":"00-handbook-introduction/genai-llm-map","title":"The GenAI & LLM Documentation Map","description":"This map provides a visual overview of how the different components of the GenAI & LLM Handbook connect, guiding your learning and application.","permalink":"/gen-ai-llm-docs/docs/00-handbook-introduction/genai-llm-map"},{"id":"04-responsible-ai/threat-model-lite","title":"Threat Model Lite","description":"Quickly identify and mitigate security risks associated with AI-assisted development. This lightweight threat modeling approach focuses on AI-specific vulnerabilities and ensures that security considerations are embedded early in the GenAI & LLM Documentation Loop.","permalink":"/gen-ai-llm-docs/docs/04-responsible-ai/threat-model-lite"},{"id":"01-handbook-core-method/07-tool-use-and-agents","title":"Tool Use and Agents","description":"Move beyond natural language generation to enable LLMs to produce data in predictable formats (e.g., JSON, YAML, XML) and interact with external systems (APIs, databases). This is essential for integrating LLMs into automated workflows and building reliable AI-assisted applications.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/07-tool-use-and-agents"},{"id":"05-tooling-and-frameworks/00-tooling-index","title":"Tooling Index","description":"The tool is not the method. A carpenter can use a hand saw or a power saw, but the geometry of the cut remains the same. GenAI & LLM Documentation works with any tool that allows context injection and structured interaction.","permalink":"/gen-ai-llm-docs/docs/05-tooling-and-frameworks/00-tooling-index"},{"id":"00-handbook-introduction/what-is-genai-llm","title":"What is GenAI & LLM?","description":"The GenAI & LLM Handbook is for people who want the speed of GenAI without giving up clarity, correctness, or responsibility.","permalink":"/gen-ai-llm-docs/docs/00-handbook-introduction/what-is-genai-llm"},{"id":"00-handbook-introduction/who-this-is-for","title":"Who This Is For","description":"The GenAI & LLM Handbook is for people who want the speed of GenAI without giving up clarity, correctness, or responsibility.","permalink":"/gen-ai-llm-docs/docs/00-handbook-introduction/who-this-is-for"},{"id":"01-handbook-core-method/working-agreements-for-teams","title":"Working Agreements for Teams","description":"Establish clear, shared rules for how a team will collaborate with AI. These agreements foster a culture of accountability, trust, and effective AI integration, preventing friction and maximizing the benefits of GenAI & LLM Documentation.","permalink":"/gen-ai-llm-docs/docs/01-handbook-core-method/working-agreements-for-teams"}],"unlisted":false}}')}}]);